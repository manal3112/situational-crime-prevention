# -*- coding: utf-8 -*-
"""Hypothesis_testing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IywJLxGieDLXbHAzW76oDrHequWh-cAI
"""

import pyspark
import sys
import csv
import ast
import numpy as np
import math
from scipy.stats import t

COUNTIES_DATA_PATH = "/content/drive/MyDrive/BDA/CSE_545_Project/Other_data/all_counties_df.csv"
UNEMPLOYMENT_DATA_PATH = "/content/drive/MyDrive/BDA/CSE_545_Project/Other_data/Unemployment.csv"

sc = pyspark.SparkContext()

counties_data = sc.textFile(COUNTIES_DATA_PATH)
unemployment_data = sc.textFile(UNEMPLOYMENT_DATA_PATH)
counties_data = counties_data.mapPartitions(lambda line: csv.reader(line))
unemployment_data = unemployment_data.mapPartitions(lambda line: csv.reader(line))

counties_data_header = counties_data.first()
unemployment_data_header = unemployment_data.first()

counties_data_header_dict = {k.strip(): v for v, k in enumerate(counties_data_header)}
unemployment_data_header_dict = {k.strip(): v for v, k in enumerate(unemployment_data_header)}

def create_county_tuples(tup):
  fips_code = tup[counties_data_header_dict['FIPS_Code']]
  year = tup[counties_data_header_dict['Year']]
  for key, value in counties_data_header_dict.items():
    if key not in ['FIPS_Code', 'Year']:
      yield ((int(fips_code), int(year)), (key, float(tup[value])))

def create_unemployment_tuples(tup):
  fips_code = tup[unemployment_data_header_dict['FIPS_Code']]
  year_names = ['2001', '2002', '2003', '2004', '2005']
  for year_name in year_names:
    col_name = 'Unemployment_rate_' + year_name
    rate = tup[unemployment_data_header_dict[col_name]].strip()
    if len(rate) > 0:
      yield ((int(fips_code), int(year_name[-1])), float(rate))

def get_correlation_val(data):
  offence_code = data[0]
  arrest_rate = []
  unemployment_rate = []
  for arrest_val, unemploy_val in data[1]:
    arrest_rate.append(arrest_val)
    unemployment_rate.append(unemploy_val)
  corr = np.corrcoef(arrest_rate, unemployment_rate)
  return (offence_code, (corr[0][1], len(arrest_rate) - 2))

def get_p_values(tup):
  offence_type = tup[0]
  correction_val = 43 # Number of offence codes
  pearson_corr, df = tup[1]
  t_stat = pearson_corr/math.sqrt((1 - (pearson_corr**2))/df)
  p_value = 2 * (1 - t.cdf(abs(t_stat), df))
  corrected_p_value = p_value * correction_val
  return (offence_type, (pearson_corr, p_value, corrected_p_value))

counties_temp = counties_data.filter(lambda row: row != counties_data_header).flatMap(lambda t: create_county_tuples(t))
unemployment_temp = unemployment_data.filter(lambda row: row != unemployment_data_header).flatMap(lambda t: create_unemployment_tuples(t))

joined_data = unemployment_temp.join(counties_temp)
grouped_joined_data = joined_data.groupByKey().mapValues(list)
flattened_grouped_joined_data = grouped_joined_data.flatMap(lambda tup: tup[1])
flattened_grouped_joined_data = flattened_grouped_joined_data.map(lambda tup: (tup[1][0], (tup[1][1], tup[0])))
grouped_by_offence_type = flattened_grouped_joined_data.groupByKey().mapValues(list)
corr_list = grouped_by_offence_type.map(lambda tup: get_correlation_val(tup)).map(lambda tup: get_p_values(tup)).collect()
print(sorted(corr_list, key=lambda tup: tup[1][0], reverse=True))
